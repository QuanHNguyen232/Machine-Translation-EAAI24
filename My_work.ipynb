{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Note"
      ],
      "metadata": {
        "id": "eXDGxy9cuQRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done basic steps, but how to improve performance (not good as [tutorial](https://www.youtube.com/watch?v=EoGUlvhRYpk) - non Attention):\n",
        "* Apply beam search [pcyin Github](https://github.com/pcyin/pytorch_basic_nmt)\n",
        "* padding base on [likarajo Github](https://github.com/likarajo/language_translation)\n",
        "* use pretrained word embedding [likarajo Github](https://github.com/likarajo/language_translation)\n",
        "* Add Attention into model (next [tutorial](https://www.youtube.com/watch?v=sQUqQddQtB4))"
      ],
      "metadata": {
        "id": "SFU41gbJuRnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "JsG8au9fTrrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "fqXy6OQ5TyHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dede04cc-65fb-49e5-de2c-743d357fb128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy -q"
      ],
      "metadata": {
        "id": "ywcGEaL2Tyfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download fr_core_news_sm -q\n",
        "# !python -m spacy download en_core_web_sm -q\n",
        "# !python -m spacy download de_core_news_sm -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QriVEe-lUF-l",
        "outputId": "9498c5ed-10ee-419f-ba59-52fe2e5bc32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-05 22:26:58.714744: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-05 22:27:15.574698: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9Bq0bp8ET1fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSCdad8U3coN",
        "outputId": "12b6853e-9af0-468e-b73f-af293b3ed5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "lOPhzBoLT31u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "VVZqR6o8T5CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 19WMw9e1J7EELfTeGB0k8rIbksudEg6Kk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emwZPS_7T8KP",
        "outputId": "a8121a5f-6aec-4499-a9b0-53d3a05e7618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19WMw9e1J7EELfTeGB0k8rIbksudEg6Kk\n",
            "To: /content/eng-fra.txt\n",
            "100% 9.54M/9.54M [00:00<00:00, 49.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.max_len = 0\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {2:\"<PAD>\", 0: \"<SOS>\", 1: \"<EOS>\"}\n",
        "        self.n_words = 3  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index: # if not in dict:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else: # count++ if word already in dict\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "k5Iw-vq8VwhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readLangs(lang1='eng', lang2='fra', reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    # /content/gdrive/MyDrive/Colab Notebooks/eaai24/eng-fra.txt\n",
        "    lines = open('./%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "SRgWl3USVIEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 128*100\n",
        "\n",
        "def filterPair(p):\n",
        "  # p: a pair of lang\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "qHVgLJKFXPFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.max_len = max(input_lang.max_len, len(pair[0]))\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.max_len = max(output_lang.max_len, len(pair[1]))\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "gFknXd37VL8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 256*2"
      ],
      "metadata": {
        "id": "1LlFSwaAY1g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "nfw8QTrGT8UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    input_tensor = input_tensor.permute(1, 0)\n",
        "    pad = (0, MAX_LENGTH - input_tensor.shape[1])\n",
        "    input_tensor = F.pad(input_tensor, pad, \"constant\", PAD_token)\n",
        "\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    target_tensor = target_tensor.permute(1, 0)\n",
        "    pad = (0, MAX_LENGTH - target_tensor.shape[1])\n",
        "    target_tensor = F.pad(target_tensor, pad, \"constant\", PAD_token)\n",
        "    # output.shape = (512)\n",
        "    return (input_tensor.permute(1, 0).squeeze(), target_tensor.permute(1, 0).squeeze())"
      ],
      "metadata": {
        "id": "S9y3dEYeX6CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pair = random.choice(pairs)\n",
        "# print(pair)\n",
        "# print(len(tensorsFromPair(pair)))\n",
        "# print(tensorsFromPair(pair)[0].shape, tensorsFromPair(pair)[1].shape)\n",
        "# print(tensorsFromPair(pair)[0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWM9ymdVZLrp",
        "outputId": "48abfb73-1e8c-4357-a4d3-59b978da5d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['compare tes reponses avec celles du professeur .', 'compare your answers with the teacher s .']\n",
            "2\n",
            "torch.Size([512, 1]) torch.Size([512, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, input_lang, output_lang, pairs):\n",
        "    self.input_lang = input_lang\n",
        "    self.output_lang = output_lang\n",
        "    self.pairs = pairs\n",
        "    self.MAX_LENGTH = 512\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.pairs)\n",
        "  \n",
        "  def indexesFromSentence(self, lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "  def tensorFromSentence(self, lang, sentence):\n",
        "    indexes = self.indexesFromSentence(lang, sentence)\n",
        "    indexes.insert(0, SOS_token)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "  def tensorsFromPair(self, pair):\n",
        "    input_tensor = self.tensorFromSentence(self.input_lang, pair[0])  # shape = (seq_len, 1)\n",
        "    input_tensor = input_tensor.permute(1, 0) # shape = (1, seq_len)\n",
        "    pad = (0, self.MAX_LENGTH - input_tensor.shape[1])\n",
        "    input_tensor = F.pad(input_tensor, pad, \"constant\", PAD_token)  # shape = (MAX_LENGTH, 1)\n",
        "\n",
        "    target_tensor = self.tensorFromSentence(self.output_lang, pair[1])\n",
        "    target_tensor = target_tensor.permute(1, 0)\n",
        "    pad = (0, self.MAX_LENGTH - target_tensor.shape[1])\n",
        "    target_tensor = F.pad(target_tensor, pad, \"constant\", PAD_token)\n",
        "    # out.shape = [512]\n",
        "    return (input_tensor.permute(1, 0).squeeze(), target_tensor.permute(1, 0).squeeze())\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    pair = self.pairs[index]\n",
        "    return (self.tensorsFromPair(pair), pair)"
      ],
      "metadata": {
        "id": "lS7l0yosZePD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "dataset = MyDataset(input_lang, output_lang, pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEK6Z94Cc-8v",
        "outputId": "baff789c-1ab6-4620-dd17-92f7dbc22f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 135842 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 21335\n",
            "eng 13044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(en_vec, fr_vec), (en, fr) = dataset[15]\n",
        "en, fr, en_vec.shape, fr_vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAQqtPOmdkJk",
        "outputId": "4d4cbeb7-1f6b-4873-8551-c6d696aa5291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('je l ai emporte !', 'i won !', torch.Size([512]), torch.Size([512]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "QtoLKAg_d-cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (en_vec, fr_vec), (en, fr) in dataloader:\n",
        "  print(en_vec.shape, fr_vec.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsrLigtmeWWP",
        "outputId": "c660058a-3ebc-4b1f-c35f-129527f16b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 512]) torch.Size([64, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang.n_words, output_lang.n_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52newnDfaKk",
        "outputId": "1adf0ef4-2d2a-4376-ba49-7f362f5bd743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21335, 13044)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 300\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "p = 0.5\n",
        "embedding = nn.Embedding(input_lang.n_words, embedding_size, padding_idx=PAD_token)\n",
        "dropout = nn.Dropout(p)\n",
        "lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)"
      ],
      "metadata": {
        "id": "v2Ryqngnfqy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vec = en_vec.squeeze().permute(1, 0)\n",
        "# en_vec.shape = (seq_len, batch_size)\n",
        "en_vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqbpLkKuiEEj",
        "outputId": "dbe73f35-d1ee-4bc2-f444-4af089252585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  embed = embedding(en_vec)\n",
        "  outputs, (hidden, cell) = lstm(dropout(embed))\n",
        "  print(embed.shape, outputs.shape, hidden.shape, cell.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJb9VONgfy1C",
        "outputId": "54f10318-2fc7-435a-925c-5893ec2c85e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 64, 300]) torch.Size([512, 64, 256]) torch.Size([2, 64, 256]) torch.Size([2, 64, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "2i1_2r_wfBaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "DCqhftYcfEdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    '''\n",
        "    Args:\n",
        "      input_size: size of Vocabulary\n",
        "      embedding_size: size of vec for word2vec\n",
        "      hidden_size: 1024\n",
        "      num_layers: 2\n",
        "      p: dropout rate = 0.5\n",
        "    '''\n",
        "    super(Encoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size) # output can be (batch, sent_len, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Args:\n",
        "      x: has shape = (seq_len, batch_size)\n",
        "\n",
        "    Return:\n",
        "      hidden: shape = (D∗num_layers, batch_size, hidden_size if proj_size<=0 else proj_size)\n",
        "      cell: shape = (D∗num_layers, bact_size, hidden_size)\n",
        "    '''\n",
        "    # print(f'Encoder\\t x.shape = {x.shape} \\t expect (512, batch_size)')\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # print(f'Encoder\\t embedding.shape = {embedding.shape} \\t expect (512, batch_size, 300)')\n",
        "\n",
        "    # embedding shape = (seq_len, batch_size, embedding_size)\n",
        "    # LSTM input: shape = (seq_len, batch_size, input_size)\n",
        "    outputs, (hidden, cell) = self.rnn(embedding) # outputs shape: (seq_length, N, hidden_size)\n",
        "    # print(f'Encoder\\t hidden.shape = {hidden.shape} \\t expect ({self.num_layers}, batch_size, {self.hidden_size})')\n",
        "    # print(f'Encoder\\t cell.shape = {cell.shape} \\t expect ({self.num_layers}, batch_size, {self.hidden_size})')\n",
        "\n",
        "    return hidden, cell # error in return shape (expect 2D)"
      ],
      "metadata": {
        "id": "5rmOl71_fKDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "e-emBdTTfElr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\n",
        "    '''\n",
        "    input_size: size of Vocabulary\n",
        "    embedding_size: size of vec for word2vec\n",
        "    hidden_size: same as in Encoder\n",
        "    output_size: size of Eng vocab (in case of Ger -> Eng)\n",
        "    num_layers:\n",
        "    p: dropout rate\n",
        "    '''\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    '''\n",
        "    Args:\n",
        "      x: shape = (batch_size) because we input 1 word each time\n",
        "      hidden: shape = (D * num_layers, hidden_size)\n",
        "      cell: current state (for next pred)\n",
        "    \n",
        "    Return:\n",
        "      pred: shape = (batch_size, target_vocab_len)\n",
        "      hidden, cell: state for next pred\n",
        "    '''\n",
        "    # print(f'Decoder\\tx.shape = {x.shape} \\t expect (batch_size)')\n",
        "    x = x.unsqueeze(0)  # shape = (1, batch_size) = (seq_len, batch_size) since we use a single word and not a sentence\n",
        "    # print(f'Decoder\\tx.shape = {x.shape} \\t expect (1, batch_size)')\n",
        "    \n",
        "    embedding = self.dropout(self.embedding(x)) # embedding shape = (1, batch_size, embedding_size)\n",
        "    # print(f'Decoder\\t embedding.shape = {embedding.shape} \\t expect (1, batch_size, 300)')\n",
        "    # print(f'Decoder\\t hidden.shape = {hidden.shape} \\t cell.shape = {cell.shape}')\n",
        "    outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell)) # outputs shape = (1, batch_size, hidden_size)\n",
        "    # print(f'Decoder\\t outputs.shape = {outputs.shape} \\t expect (1, batch_size, {self.hidden_size})')\n",
        "\n",
        "    predictions = self.fc(outputs)  # predictions.shape = (1, batch_size, vocab_len)\n",
        "    predictions = predictions.squeeze(0)  # predictions.shape = (batch_size, target_vocab_len) to send to loss func\n",
        "    # print(f'Decoder\\t predictions.shape = {predictions.shape} \\t expect (batch_size, target_vocab_len)')\n",
        "    return predictions, hidden, cell"
      ],
      "metadata": {
        "id": "fhwvFK2jfKvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq"
      ],
      "metadata": {
        "id": "QVbTx2UvfIIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder: torch.nn.Module, decoder: torch.nn.Module):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "    '''\n",
        "    source: shape = (src_len, batch_size)\n",
        "    target: shape = (target_len, batch_size)\n",
        "    teacher_force_ratio: ratio b/w choosing predicted and ground_truth word to use as input for next word prediction\n",
        "    '''\n",
        "    batch_size = source.shape[1]  # need modification\n",
        "    target_len = target.shape[0]  # need modification\n",
        "    target_vocab_size = output_lang.n_words  # need modification (len of target vocab)\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device) # use as output prediction, init w/ zeros\n",
        "\n",
        "    hidden, cell = self.encoder(source)\n",
        "\n",
        "    # Grab the first input to the Decoder which will be <SOS> token\n",
        "    x = target[0]\n",
        "    # print(f'Seq2Seq\\t start x.shape = {x.shape} \\t expect (batch_size)')\n",
        "    for t in range(1, target_len):\n",
        "      # Use previous hidden, cell as context from encoder at start\n",
        "      output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "      # output.shape = (batch_size, target_vocab_len)\n",
        "      \n",
        "      # print(f'Seq2Seq\\t output.shape = {output.shape} \\t expect (batch_size, target_vocab_len)')\n",
        "\n",
        "      # Store next output prediction\n",
        "      outputs[t] = output\n",
        "\n",
        "      # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "      best_guess = output.argmax(1) # best_guess.shape = (batch_size)\n",
        "      # print(f'Seq2Seq\\t best_guess.shape = {best_guess.shape} \\t expect (batch_size)')\n",
        "\n",
        "      # With probability of teacher_force_ratio we take the actual next word\n",
        "      # otherwise we take the word that the Decoder predicted it to be.\n",
        "      # Teacher Forcing is used so that the model gets used to seeing\n",
        "      # similar inputs at training and testing time, if teacher forcing is 1\n",
        "      # then inputs at test time might be completely different than what the\n",
        "      # network is used to. This was a long comment.\n",
        "      x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "WK_BbwgufJiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "nMyIOy59fEqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpFiKoxPmJlv",
        "outputId": "5d110f4d-30c5-445b-df72-cb1831ebe5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 135842 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 21335\n",
            "eng 13044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "# Model hyperparameters\n",
        "load_model = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size_encoder = input_lang.n_words\n",
        "input_size_decoder = output_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 256  # Needs to be the same for both RNN's\n",
        "num_layers = 2\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5"
      ],
      "metadata": {
        "id": "7wT5iQoGfEt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 500\n",
        "data_len = int(6400/2)\n",
        "pairs = pairs[start_id : start_id + data_len]\n",
        "dataset = MyDataset(input_lang, output_lang, pairs)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "QJGBd6pemQNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (en_vec, fr_vec), (en, fr) in dataloader:\n",
        "  print(en_vec.shape, fr_vec.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMyLgc40mb0w",
        "outputId": "93faf7a5-8216-40a8-ba87-0eafa3e4c1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 512]) torch.Size([64, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)"
      ],
      "metadata": {
        "id": "lEX0d9GloCVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)"
      ],
      "metadata": {
        "id": "S1vuP_ZWnBhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)"
      ],
      "metadata": {
        "id": "5Llv4QySnDrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(encoder_net, decoder_net).to(device)"
      ],
      "metadata": {
        "id": "upjvAx7jn-VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "hlmsOWiZoBhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  # print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  for batch_idx, ((en_vec, fr_vec), (en, fr)) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "    en_vec, fr_vec = en_vec.permute(1, 0), fr_vec.permute(1, 0)\n",
        "    en_vec = en_vec.to(device)\n",
        "    fr_vec = fr_vec.to(device)\n",
        "\n",
        "    # Forward prop\n",
        "    output = model(en_vec, fr_vec)\n",
        "\n",
        "    # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "    # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "    # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "    # way that we have output_words * batch_size that we want to send in into\n",
        "    # our cost function, so we need to do some reshapin. While we're at it\n",
        "    # Let's also remove the start token while we're at it\n",
        "    output = output[1:].reshape(-1, output.shape[2])  # shape = (trg_len * batch_size, output_dim)\n",
        "    target = fr_vec[1:].reshape(-1) # shape = (trg_len * batch_size)\n",
        "    # output[1:]: ignore SOS_token\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "    \n",
        "    total_loss += loss.item()\n",
        "  print(f\"EPOCH = {epoch} \\t loss = {total_loss/len(dataloader)}\")"
      ],
      "metadata": {
        "id": "UaHNnlmfoJqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 100%|██████████| 50/50 [07:26<00:00,  8.94s/it]\n",
        "# EPOCH = 0 \t loss = 5.383958940505981\n",
        "# 100%|██████████| 50/50 [07:25<00:00,  8.90s/it]\n",
        "# EPOCH = 1 \t loss = 3.7594539594650267\n",
        "# 100%|██████████| 50/50 [07:25<00:00,  8.90s/it]\n",
        "# EPOCH = 2 \t loss = 3.5973013925552366\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.90s/it]\n",
        "# EPOCH = 3 \t loss = 3.478486728668213\n",
        "# 100%|██████████| 50/50 [07:25<00:00,  8.90s/it]\n",
        "# EPOCH = 4 \t loss = 3.4210835123062133\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n",
        "# EPOCH = 5 \t loss = 3.356914539337158\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.90s/it]\n",
        "# EPOCH = 6 \t loss = 3.2783570289611816\n",
        "# 100%|██████████| 50/50 [07:23<00:00,  8.87s/it]\n",
        "# EPOCH = 7 \t loss = 3.2372921180725096\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.89s/it]\n",
        "# EPOCH = 8 \t loss = 3.199459252357483\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.89s/it]\n",
        "# EPOCH = 9 \t loss = 3.1788624906539917\n",
        "# 100%|██████████| 50/50 [07:23<00:00,  8.87s/it]\n",
        "# EPOCH = 10 \t loss = 3.1831029272079467\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n",
        "# EPOCH = 11 \t loss = 3.1025032949447633\n",
        "# 100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n",
        "# EPOCH = 12 \t loss = 3.1095044803619385\n",
        "# 100%|██████████| 50/50 [07:23<00:00,  8.86s/it]\n",
        "# EPOCH = 13 \t loss = 3.0869728183746337\n",
        "# 100%|██████████| 50/50 [07:22<00:00,  8.86s/it]\n",
        "# EPOCH = 14 \t loss = 3.08543803691864\n",
        "# 100%|██████████| 50/50 [07:22<00:00,  8.84s/it]\n",
        "# EPOCH = 15 \t loss = 3.0724154567718505\n",
        "# 100%|██████████| 50/50 [07:21<00:00,  8.83s/it]\n",
        "# EPOCH = 16 \t loss = 3.0756219959259035\n",
        "# 100%|██████████| 50/50 [07:22<00:00,  8.85s/it]\n",
        "# EPOCH = 17 \t loss = 3.017907304763794\n",
        "# 100%|██████████| 50/50 [07:21<00:00,  8.84s/it]\n",
        "# EPOCH = 18 \t loss = 3.0001839065551756\n",
        "# 100%|██████████| 50/50 [07:22<00:00,  8.85s/it]\n",
        "# EPOCH = 19 \t loss = 3.021025981903076\n",
        "# 100%|██████████| 50/50 [07:22<00:00,  8.84s/it]\n",
        "# EPOCH = 20 \t loss = 2.9646836137771606\n",
        "# 100%|██████████| 50/50 [07:22<00:00,  8.84s/it]\n",
        "# EPOCH = 21 \t loss = 2.98474328994751\n",
        "#  28%|██▊       | 14/50 [02:12<05:40,  9.47s/it]\n"
      ],
      "metadata": {
        "id": "LzikB9E6kSFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ],
      "metadata": {
        "id": "ckzBiGAPlYon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, en_vec, output_lang, device, max_length=50):\n",
        "  model.eval()\n",
        "  vec = en_vec[0]\n",
        "  vec = vec.unsqueeze(0)\n",
        "  \n",
        "  # Build encoder hidden, cell state\n",
        "  with torch.no_grad():\n",
        "      hidden, cell = model.encoder(vec)\n",
        "\n",
        "  outputs = [SOS_token]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "      previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "          best_guess = output.argmax(1).item()\n",
        "\n",
        "      outputs.append(best_guess)\n",
        "\n",
        "      # Model predicts it's the end of the sentence\n",
        "      if output.argmax(1).item() == EOS_token:\n",
        "          break\n",
        "  \n",
        "  print(outputs)\n",
        "  translated_sentence = [output_lang.index2word[idx] for idx in outputs]\n",
        "\n",
        "  # remove start token\n",
        "  return translated_sentence"
      ],
      "metadata": {
        "id": "ObAqABe0kVc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = MyDataset(input_lang, output_lang, pairs[-651:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1)"
      ],
      "metadata": {
        "id": "ZTvQvj5llbP-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, en_vec, output_lang, device, max_length=50):\n",
        "  model.eval()\n",
        "  vec = en_vec[0]\n",
        "  vec = vec.unsqueeze(0)\n",
        "  vec = vec.permute(1, 0)\n",
        "  # print(vec.shape)\n",
        "\n",
        "  # Build encoder hidden, cell state\n",
        "  with torch.no_grad():\n",
        "      hidden, cell = model.encoder(vec)\n",
        "      # print(hidden.shape, cell.shape)\n",
        "\n",
        "  outputs = [SOS_token]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "      previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "          best_guess = output.argmax(1).item()\n",
        "\n",
        "      outputs.append(best_guess)\n",
        "\n",
        "      # Model predicts it's the end of the sentence\n",
        "      if output.argmax(1).item() == EOS_token:\n",
        "          break\n",
        "\n",
        "  translated_sentence = [output_lang.index2word[idx] for idx in outputs]\n",
        "  print(translated_sentence)\n",
        "  return translated_sentence"
      ],
      "metadata": {
        "id": "osrvtFRflNDZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, ((en_vec, fr_vec), (en, fr)) in enumerate(testloader):\n",
        "  # print(en_vec.shape, fr_vec.shape)\n",
        "  # print(en[0], en_vec[0][:10])\n",
        "  print(fr[0])\n",
        "  translate_sentence(model, en_vec, output_lang, device, max_length=50)\n",
        "  if idx==50: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3pZT6IHlfzz",
        "outputId": "b6870dc5-2b7d-4f40-c5d4-52a6712ed8a3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i must hurry .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i must leave .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i must leave .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i must study .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a car .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a hug .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a job .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a job .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a job .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a map .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need a pen .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need money .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need paint .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need paint .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need proof .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need proof .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need sleep .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need space .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need sugar .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need to go .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need to go .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need to go .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need water .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i need water .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i never lose .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i often read .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i play piano .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i read books .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i rewrote it .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i rewrote it .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i said maybe .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i see a book .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i see a lion .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i see a rose .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i sell shoes .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i started it .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i started it .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i started it .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i started it .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i still care .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i suppose so .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i sympathize .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i teach here .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i thought so .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i took risks .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i tried hard .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i tried that .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i understand .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i understood .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i want a lot .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n",
            "i want a lot .\n",
            "['<SOS>', 'i', 'm', '.', '.', '<EOS>']\n"
          ]
        }
      ]
    }
  ]
}