{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Note"
      ],
      "metadata": {
        "id": "eXDGxy9cuQRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done basic steps, but how to improve performance (not good as [tutorial](https://www.youtube.com/watch?v=EoGUlvhRYpk) - non Attention):\n",
        "* [ ] Apply beam search [pcyin Github](https://github.com/pcyin/pytorch_basic_nmt)\n",
        "* [X] Padding base on [likarajo Github](https://github.com/likarajo/language_translation)\n",
        "* [ ] Use pretrained word embedding [likarajo Github](https://github.com/likarajo/language_translation)\n",
        "* [ ] Add Attention into model (next [tutorial](https://www.youtube.com/watch?v=sQUqQddQtB4))\n",
        "* [ ] Use pretrained Tokenizer (Spacy)\n",
        "\n",
        "Original paper [Seq2Seq](https://arxiv.org/pdf/1409.3215.pdf)\n",
        "* [ ] Use 4 layers of LSTM\n",
        "* [ ] Reversing the Source Sentences () --> how about padding?\n",
        "* [X] Although LSTMs can have exploding gradients. Thus we enforced a hard constraint on the norm of the gradient [10,25] by scaling it when its norm exceeded a threshold.\n",
        "* [ ]  Initialized all of the LSTM’s parameters with the uniform distribution between -0.08 and 0.08 (check [stackoverflow](https://stackoverflow.com/questions/55276504/different-methods-for-initializing-embedding-layer-weights-in-pytorch) OR [documen](https://pytorch.org/docs/stable/nn.init.html_))"
      ],
      "metadata": {
        "id": "SFU41gbJuRnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "JsG8au9fTrrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "fqXy6OQ5TyHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c667f9-f828-4190-d6f0-5089df7cfad5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gok_Xr_E5ow2",
        "outputId": "eca47a3d-2ccb-43b8-baff-a68cd5868bb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy -q"
      ],
      "metadata": {
        "id": "ywcGEaL2Tyfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download fr_core_news_sm -q\n",
        "# !python -m spacy download en_core_web_sm -q\n",
        "# !python -m spacy download de_core_news_sm -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QriVEe-lUF-l",
        "outputId": "9498c5ed-10ee-419f-ba59-52fe2e5bc32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-05 22:26:58.714744: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-05 22:27:15.574698: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "9Bq0bp8ET1fL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8297215-1b70-4476-90cf-d39d97991b40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "lOPhzBoLT31u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "VVZqR6o8T5CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 19WMw9e1J7EELfTeGB0k8rIbksudEg6Kk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emwZPS_7T8KP",
        "outputId": "55357f0f-9e61-41c5-c8fc-de147bc064e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19WMw9e1J7EELfTeGB0k8rIbksudEg6Kk\n",
            "To: /content/eng-fra.txt\n",
            "100% 9.54M/9.54M [00:00<00:00, 42.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.max_len = 0\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0:\"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
        "        self.n_words = 3  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index: # if not in dict:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else: # count++ if word already in dict\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "k5Iw-vq8VwhI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readLangs(lang1='eng', lang2='fra', reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    # /content/gdrive/MyDrive/Colab Notebooks/eaai24/eng-fra.txt\n",
        "    lines = open('./%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "SRgWl3USVIEa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 128\n",
        "\n",
        "def filterPair(p):\n",
        "  # p: a pair of lang\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "qHVgLJKFXPFY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.max_len = max(input_lang.max_len, len(pair[0]))\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.max_len = max(output_lang.max_len, len(pair[1]))\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "gFknXd37VL8b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "nfw8QTrGT8UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def indexesFromSentence(lang, sentence):\n",
        "#     return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "# def tensorFromSentence(lang, sentence):\n",
        "#     indexes = indexesFromSentence(lang, sentence)\n",
        "#     indexes.insert(0, SOS_token)\n",
        "#     indexes.append(EOS_token)\n",
        "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(1,-1)\n",
        "\n",
        "# def tensorsFromPair(pair):\n",
        "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "#     input_tensor = pad_sequences(input_tensor, maxlen=MAX_LENGTH, padding='pre')\n",
        "#     # input_tensor = input_tensor.permute(1, 0)\n",
        "#     # pad = (0, MAX_LENGTH - input_tensor.shape[1])\n",
        "#     # input_tensor = F.pad(input_tensor, pad, \"constant\", PAD_token)\n",
        "\n",
        "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "#     target_tensor = pad_sequences(target_tensor, maxlen=MAX_LENGTH, padding='post')\n",
        "#     # target_tensor = target_tensor.permute(1, 0)\n",
        "#     # pad = (0, MAX_LENGTH - target_tensor.shape[1])\n",
        "#     # target_tensor = F.pad(target_tensor, pad, \"constant\", PAD_token)\n",
        "#     # output.shape = (512)\n",
        "#     return (input_tensor.squeeze(), target_tensor.squeeze())"
      ],
      "metadata": {
        "id": "S9y3dEYeX6CZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_lang, output_lang, pairs = prepareData('eng', 'fra', reverse=False)"
      ],
      "metadata": {
        "id": "hWM9ymdVZLrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pair = random.choice(pairs)\n",
        "# print(pair)\n",
        "# print(len(tensorsFromPair(pair)))\n",
        "# print(tensorsFromPair(pair)[0].shape, tensorsFromPair(pair)[1].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIOAq9ds60kK",
        "outputId": "d6cab15a-e107-4b1f-af12-41cd8762ffc3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i have enjoyed reading this novel .', 'ce roman m a bien plu .']\n",
            "2\n",
            "(128,) (128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, input_lang, output_lang, pairs, max_len=128, reverse_input=False):\n",
        "    self.input_lang = input_lang\n",
        "    self.output_lang = output_lang\n",
        "    self.pairs = pairs\n",
        "    self.MAX_LENGTH = max_len\n",
        "    self.reverse_input = reverse_input\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.pairs)\n",
        "  \n",
        "  def indexesFromSentence(self, lang, sentence):\n",
        "    return [SOS_token] + [lang.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "  def paddingTensorFromSentence(self, lang, sentence, padding='pre', reverse_in=False):\n",
        "      indexes = self.indexesFromSentence(lang, sentence)\n",
        "      remain_len = self.MAX_LENGTH - len(indexes)\n",
        "      if reverse_in:\n",
        "        indexes = list(reversed(indexes))\n",
        "        # padding = 'post'  # assumption from paper Seq2Seq: false\n",
        "\n",
        "      if padding == 'pre':\n",
        "        indexes = [PAD_token]*remain_len + indexes\n",
        "      elif padding == 'post':\n",
        "        indexes = indexes + [PAD_token]*remain_len\n",
        "      else:\n",
        "        indexes = indexes\n",
        "      return torch.tensor(indexes, dtype=torch.long, device=device).view(-1)\n",
        "\n",
        "  def tensorsFromPair(self, pair):\n",
        "      input_tensor = self.paddingTensorFromSentence(self.input_lang, pair[0], 'pre', reverse_in=self.reverse_input)\n",
        "      target_tensor = self.paddingTensorFromSentence(self.output_lang, pair[1], 'post')\n",
        "      \n",
        "      return (input_tensor, target_tensor)  # output.shape = (128)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    pair = self.pairs[index]\n",
        "    return (self.tensorsFromPair(pair), pair)"
      ],
      "metadata": {
        "id": "lS7l0yosZePD"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEK6Z94Cc-8v",
        "outputId": "1e464761-a3da-417b-bef1-bad2847a70e0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 135842 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 13044\n",
            "fra 21335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MyDataset(input_lang, output_lang, pairs, 10)"
      ],
      "metadata": {
        "id": "UrTHCxA3CCOi"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(en_vec, fr_vec), (en, fr) = dataset[213]\n",
        "print(en, fr, en_vec.shape, fr_vec.shape)\n",
        "en_vec, fr_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAQqtPOmdkJk",
        "outputId": "086d5e22-ff4e-4408-f13f-adcedf58f7c3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get down . lachez vous ! torch.Size([10]) torch.Size([10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  0,   0,   0,   0,   0,   1,  21, 103,   4,   2]),\n",
              " tensor([  1, 211, 128,   4,   2,   0,   0,   0,   0,   0]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "QtoLKAg_d-cg"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (en_vec, fr_vec), (en, fr) in dataloader:\n",
        "  print(en_vec.shape, fr_vec.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsrLigtmeWWP",
        "outputId": "31b749fb-fac6-4c77-d006-b1d7c16cc9b0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10]) torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang.n_words, output_lang.n_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52newnDfaKk",
        "outputId": "0cf50599-c4c0-43b6-8b87-2a8e2b5aa9d5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13044, 21335)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 300\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "p = 0.5\n",
        "embedding = nn.Embedding(input_lang.n_words, embedding_size, padding_idx=PAD_token)\n",
        "dropout = nn.Dropout(p)\n",
        "lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)"
      ],
      "metadata": {
        "id": "v2Ryqngnfqy6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vec = en_vec.squeeze().permute(1, 0)\n",
        "# en_vec.shape = (seq_len, batch_size)\n",
        "en_vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqbpLkKuiEEj",
        "outputId": "42e2af4d-49be-423d-a540-5ab22d7056c9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  embed = embedding(en_vec)\n",
        "  outputs, (hidden, cell) = lstm(dropout(embed))\n",
        "  print(embed.shape, outputs.shape, hidden.shape, cell.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJb9VONgfy1C",
        "outputId": "4c9ca5de-7be7-4212-9aea-56f400d07ca7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 64, 300]) torch.Size([128, 64, 256]) torch.Size([2, 64, 256]) torch.Size([2, 64, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "2i1_2r_wfBaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "DCqhftYcfEdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    '''\n",
        "    Args:\n",
        "      input_size: size of Vocabulary\n",
        "      embedding_size: size of vec for word2vec\n",
        "      hidden_size: 1024\n",
        "      num_layers: 2\n",
        "      p: dropout rate = 0.5\n",
        "    '''\n",
        "    super(Encoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size) # output can be (batch, sent_len, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Args:\n",
        "      x: has shape = (seq_len, batch_size)\n",
        "\n",
        "    Return:\n",
        "      hidden: shape = (D∗num_layers, batch_size, hidden_size if proj_size<=0 else proj_size)\n",
        "      cell: shape = (D∗num_layers, bact_size, hidden_size)\n",
        "    '''\n",
        "    # print(f'Encoder\\t x.shape = {x.shape} \\t expect (512, batch_size)')\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # print(f'Encoder\\t embedding.shape = {embedding.shape} \\t expect (512, batch_size, 300)')\n",
        "\n",
        "    # embedding shape = (seq_len, batch_size, embedding_size)\n",
        "    # LSTM input: shape = (seq_len, batch_size, input_size)\n",
        "    outputs, (hidden, cell) = self.rnn(embedding) # outputs shape: (seq_length, N, hidden_size)\n",
        "    # print(f'Encoder\\t hidden.shape = {hidden.shape} \\t expect ({self.num_layers}, batch_size, {self.hidden_size})')\n",
        "    # print(f'Encoder\\t cell.shape = {cell.shape} \\t expect ({self.num_layers}, batch_size, {self.hidden_size})')\n",
        "\n",
        "    return hidden, cell # error in return shape (expect 2D)"
      ],
      "metadata": {
        "id": "5rmOl71_fKDq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "e-emBdTTfElr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\n",
        "    '''\n",
        "    input_size: size of Vocabulary\n",
        "    embedding_size: size of vec for word2vec\n",
        "    hidden_size: same as in Encoder\n",
        "    output_size: size of Eng vocab (in case of Ger -> Eng)\n",
        "    num_layers:\n",
        "    p: dropout rate\n",
        "    '''\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    '''\n",
        "    Args:\n",
        "      x: shape = (batch_size) because we input 1 word each time\n",
        "      hidden: shape = (D * num_layers, hidden_size)\n",
        "      cell: current state (for next pred)\n",
        "    \n",
        "    Return:\n",
        "      pred: shape = (batch_size, target_vocab_len)\n",
        "      hidden, cell: state for next pred\n",
        "    '''\n",
        "    # print(f'Decoder\\tx.shape = {x.shape} \\t expect (batch_size)')\n",
        "    x = x.unsqueeze(0)  # shape = (1, batch_size) = (seq_len, batch_size) since we use a single word and not a sentence\n",
        "    # print(f'Decoder\\tx.shape = {x.shape} \\t expect (1, batch_size)')\n",
        "    \n",
        "    embedding = self.dropout(self.embedding(x)) # embedding shape = (1, batch_size, embedding_size)\n",
        "    # print(f'Decoder\\t embedding.shape = {embedding.shape} \\t expect (1, batch_size, 300)')\n",
        "    # print(f'Decoder\\t hidden.shape = {hidden.shape} \\t cell.shape = {cell.shape}')\n",
        "    outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell)) # outputs shape = (1, batch_size, hidden_size)\n",
        "    # print(f'Decoder\\t outputs.shape = {outputs.shape} \\t expect (1, batch_size, {self.hidden_size})')\n",
        "\n",
        "    predictions = self.fc(outputs)  # predictions.shape = (1, batch_size, vocab_len)\n",
        "    predictions = predictions.squeeze(0)  # predictions.shape = (batch_size, target_vocab_len) to send to loss func\n",
        "    # print(f'Decoder\\t predictions.shape = {predictions.shape} \\t expect (batch_size, target_vocab_len)')\n",
        "    return predictions, hidden, cell"
      ],
      "metadata": {
        "id": "fhwvFK2jfKvs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq"
      ],
      "metadata": {
        "id": "QVbTx2UvfIIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder: torch.nn.Module, decoder: torch.nn.Module):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "    '''\n",
        "    source: shape = (src_len, batch_size)\n",
        "    target: shape = (target_len, batch_size)\n",
        "    teacher_force_ratio: ratio b/w choosing predicted and ground_truth word to use as input for next word prediction\n",
        "    '''\n",
        "    batch_size = source.shape[1]  # need modification\n",
        "    target_len = target.shape[0]  # need modification\n",
        "    target_vocab_size = output_lang.n_words  # need modification (len of target vocab)\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device) # use as output prediction, init w/ zeros\n",
        "\n",
        "    hidden, cell = self.encoder(source)\n",
        "\n",
        "    # Grab the first input to the Decoder which will be <SOS> token\n",
        "    x = target[0]\n",
        "    # print(f'Seq2Seq\\t start x.shape = {x.shape} \\t expect (batch_size)')\n",
        "    for t in range(1, target_len):\n",
        "      # Use previous hidden, cell as context from encoder at start\n",
        "      output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "      # output.shape = (batch_size, target_vocab_len)\n",
        "      \n",
        "      # print(f'Seq2Seq\\t output.shape = {output.shape} \\t expect (batch_size, target_vocab_len)')\n",
        "\n",
        "      # Store next output prediction\n",
        "      outputs[t] = output\n",
        "\n",
        "      # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "      best_guess = output.argmax(1) # best_guess.shape = (batch_size)\n",
        "      # print(f'Seq2Seq\\t best_guess.shape = {best_guess.shape} \\t expect (batch_size)')\n",
        "\n",
        "      # With probability of teacher_force_ratio we take the actual next word\n",
        "      # otherwise we take the word that the Decoder predicted it to be.\n",
        "      # Teacher Forcing is used so that the model gets used to seeing\n",
        "      # similar inputs at training and testing time, if teacher forcing is 1\n",
        "      # then inputs at test time might be completely different than what the\n",
        "      # network is used to. This was a long comment.\n",
        "      x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "WK_BbwgufJiu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "nMyIOy59fEqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpFiKoxPmJlv",
        "outputId": "69823faf-eef7-4084-b5f2-122943ca62c3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 135842 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 13044\n",
            "fra 21335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "# Model hyperparameters\n",
        "load_model = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size_encoder = input_lang.n_words\n",
        "input_size_decoder = output_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 256  # Needs to be the same for both RNN's\n",
        "num_layers = 4\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5"
      ],
      "metadata": {
        "id": "7wT5iQoGfEt7"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 500\n",
        "data_len = int(6400/2)\n",
        "pairs = pairs[start_id : start_id + data_len]\n",
        "dataset = MyDataset(input_lang, output_lang, pairs, 128, True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "QJGBd6pemQNm"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (en_vec, fr_vec), (en, fr) in dataloader:\n",
        "  print(en_vec.shape, fr_vec.shape, len(dataloader))\n",
        "  print(en_vec, fr_vec)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMyLgc40mb0w",
        "outputId": "437554ae-f4e8-4da0-8f5e-decbc4679941"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 128]) torch.Size([64, 128]) 50\n",
            "tensor([[  0,   0,   0,  ...,  23,  13,   1],\n",
            "        [  0,   0,   0,  ..., 216,  13,   1],\n",
            "        [  0,   0,   0,  ..., 216,  13,   1],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  67,  13,   1],\n",
            "        [  0,   0,   0,  ...,  67,  13,   1],\n",
            "        [  0,   0,   0,  ...,  67,  13,   1]], device='cuda:0') tensor([[  1,  22, 263,  ...,   0,   0,   0],\n",
            "        [  1,  22, 263,  ...,   0,   0,   0],\n",
            "        [  1,  22, 263,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [  1,  24, 464,  ...,   0,   0,   0],\n",
            "        [  1,  22, 465,  ...,   0,   0,   0],\n",
            "        [  1,  22, 466,  ...,   0,   0,   0]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)"
      ],
      "metadata": {
        "id": "lEX0d9GloCVQ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)"
      ],
      "metadata": {
        "id": "S1vuP_ZWnBhN"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)"
      ],
      "metadata": {
        "id": "5Llv4QySnDrC"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(encoder_net, decoder_net).to(device)"
      ],
      "metadata": {
        "id": "upjvAx7jn-VB"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "hlmsOWiZoBhT"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  # print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  for batch_idx, ((en_vec, fr_vec), (en, fr)) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "    en_vec, fr_vec = en_vec.permute(1, 0), fr_vec.permute(1, 0) # (batch_size, seq_len) ---> (seq_len, batch_size)\n",
        "    en_vec = en_vec.to(device)\n",
        "    fr_vec = fr_vec.to(device)\n",
        "\n",
        "    # Forward prop\n",
        "    output = model(en_vec, fr_vec)\n",
        "\n",
        "    # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "    # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "    # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "    # way that we have output_words * batch_size that we want to send in into\n",
        "    # our cost function, so we need to do some reshapin. While we're at it\n",
        "    # Let's also remove the start token while we're at it\n",
        "    output = output[1:].reshape(-1, output.shape[2])  # shape = (trg_len * batch_size, output_dim)\n",
        "    target = fr_vec[1:].reshape(-1) # shape = (trg_len * batch_size)\n",
        "    # output[1:]: ignore SOS_token\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "    \n",
        "    total_loss += loss.item()\n",
        "  print(f\"EPOCH = {epoch} \\t loss = {total_loss/len(dataloader)}\")"
      ],
      "metadata": {
        "id": "UaHNnlmfoJqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6e1785-abbb-4bbc-9d6c-2afc0e7c0950"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 0 \t loss = 6.046862239837647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:24<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 1 \t loss = 4.462330040931701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:22<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 2 \t loss = 4.330181069374085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 3 \t loss = 4.2650360584259035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 4 \t loss = 4.228246083259583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 5 \t loss = 4.1828292989730835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 6 \t loss = 4.147529201507568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 7 \t loss = 4.112067928314209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:23<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 8 \t loss = 4.0788923311233525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH = 9 \t loss = 4.0515174341201785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA_SIZE = 3200, epoch = 64\n",
        "\n",
        "---\n",
        "\n",
        "NEW CHANGE\n",
        "\n",
        "seq_len = 128\n",
        "\n",
        "padding = 'pre' in (reversed) and 'post' out\n",
        "\n",
        "encoder_embedding_size = 300\n",
        "\n",
        "decoder_embedding_size = 300\n",
        "\n",
        "hidden_size = 256\n",
        "\n",
        "num_layers = 4\n",
        "\n",
        "<details>\n",
        "<summary>loss log</summary>\n",
        "\n",
        "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n",
        "EPOCH = 0 \t loss = 6.046862239837647\n",
        "\n",
        "100%|██████████| 50/50 [01:24<00:00,  1.68s/it]\n",
        "EPOCH = 1 \t loss = 4.462330040931701\n",
        "\n",
        "100%|██████████| 50/50 [01:22<00:00,  1.65s/it]\n",
        "EPOCH = 2 \t loss = 4.330181069374085\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n",
        "EPOCH = 3 \t loss = 4.2650360584259035\n",
        "\n",
        "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n",
        "EPOCH = 4 \t loss = 4.228246083259583\n",
        "\n",
        "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n",
        "EPOCH = 5 \t loss = 4.1828292989730835\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n",
        "EPOCH = 6 \t loss = 4.147529201507568\n",
        "\n",
        "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]\n",
        "EPOCH = 7 \t loss = 4.112067928314209\n",
        "\n",
        "100%|██████████| 50/50 [01:23<00:00,  1.67s/it]\n",
        "EPOCH = 8 \t loss = 4.0788923311233525\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n",
        "EPOCH = 9 \t loss = 4.0515174341201785\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "NEW CHANGE (have current the best potetial)\n",
        "\n",
        "seq_len = 128\n",
        "\n",
        "padding = 'pre' in (reversed) and 'post' out\n",
        "\n",
        "encoder_embedding_size = 300\n",
        "\n",
        "decoder_embedding_size = 300\n",
        "\n",
        "hidden_size = 256\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "<details>\n",
        "<summary>loss log</summary>\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.63s/it]\n",
        "EPOCH = 0 \t loss = 6.058306541442871\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 1 \t loss = 4.408794131278992\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.59s/it]\n",
        "EPOCH = 2 \t loss = 4.23139440536499\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 3 \t loss = 4.0753618288040165\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 4 \t loss = 3.9149249458312987\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 5 \t loss = 3.7490834188461304\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 6 \t loss = 3.5651425886154176\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 7 \t loss = 3.4091691303253175\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 8 \t loss = 3.2411407709121702\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 9 \t loss = 3.092280511856079\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.59s/it]\n",
        "EPOCH = 10 \t loss = 2.956990485191345\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 11 \t loss = 2.8181574296951295\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 12 \t loss = 2.7334376478195193\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.59s/it]\n",
        "EPOCH = 13 \t loss = 2.655946660041809\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 14 \t loss = 2.5171649122238158\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 15 \t loss = 2.4004191398620605\n",
        "\n",
        "100%|██████████| 50/50 [01:20<00:00,  1.61s/it]\n",
        "EPOCH = 16 \t loss = 2.27789612531662\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 17 \t loss = 2.2217716789245605\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 18 \t loss = 2.1357618045806883\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 19 \t loss = 2.0568911695480345\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "NEW CHANGE\n",
        "\n",
        "seq_len = 128\n",
        "\n",
        "padding = 'post' in (reversed) ang 'post' out\n",
        "\n",
        "encoder_embedding_size = 300\n",
        "\n",
        "decoder_embedding_size = 300\n",
        "\n",
        "hidden_size = 256\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "<details>\n",
        "<summary>loss log</summary>\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 0 \t loss = 6.034457578659057\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 1 \t loss = 4.423784399032593\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 2 \t loss = 4.2614400625228885\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 3 \t loss = 4.154506096839905\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 4 \t loss = 4.066013298034668\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 5 \t loss = 4.006021103858948\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 6 \t loss = 3.9698329877853396\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 7 \t loss = 3.929253115653992\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 8 \t loss = 3.872750663757324\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 9 \t loss = 3.8164627838134764\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "NEW CHANGE (have current 2nd best potetial)\n",
        "\n",
        "seq_len = 128\n",
        "\n",
        "padding = 'pre' and 'post' (in and out)\n",
        "\n",
        "encoder_embedding_size = 300\n",
        "\n",
        "decoder_embedding_size = 300\n",
        "\n",
        "hidden_size = 256\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "<details>\n",
        "<summary>loss log</summary>\n",
        "\n",
        "100%|██████████| 50/50 [01:20<00:00,  1.61s/it]\n",
        "EPOCH = 0 \t loss = 6.079052228927612\n",
        "\n",
        "100%|██████████| 50/50 [01:20<00:00,  1.61s/it]\n",
        "EPOCH = 1 \t loss = 4.4093651819229125\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.62s/it]\n",
        "EPOCH = 2 \t loss = 4.234301209449768\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n",
        "EPOCH = 3 \t loss = 4.087865462303162\n",
        "\n",
        "100%|██████████| 50/50 [01:20<00:00,  1.62s/it]\n",
        "EPOCH = 4 \t loss = 3.977463812828064\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.63s/it]\n",
        "EPOCH = 5 \t loss = 3.8644219923019407\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 6 \t loss = 3.6924276685714723\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 7 \t loss = 3.5700292873382566\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 8 \t loss = 3.3947692918777466\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
        "EPOCH = 9 \t loss = 3.2692558479309084\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.63s/it]\n",
        "EPOCH = 10 \t loss = 3.1830705881118773\n",
        "\n",
        "100%|██████████| 50/50 [01:20<00:00,  1.61s/it]\n",
        "EPOCH = 11 \t loss = 3.098177933692932\n",
        "\n",
        "100%|██████████| 50/50 [01:20<00:00,  1.62s/it]\n",
        "EPOCH = 12 \t loss = 3.017664046287537\n",
        "\n",
        "100%|██████████| 50/50 [01:21<00:00,  1.63s/it]\n",
        "EPOCH = 13 \t loss = 2.8849183225631716\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 14 \t loss = 2.768659610748291\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 15 \t loss = 2.6834586668014526\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 16 \t loss = 2.6142616200447084\n",
        "\n",
        "100%|██████████| 50/50 [01:18<00:00,  1.58s/it]\n",
        "EPOCH = 17 \t loss = 2.5200012016296385\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n",
        "EPOCH = 18 \t loss = 2.476028332710266\n",
        "\n",
        "100%|██████████| 50/50 [01:19<00:00,  1.60s/it]\n",
        "EPOCH = 19 \t loss = 2.35499146938324\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "NEW CHANGE\n",
        "\n",
        "seq_len = 128\n",
        "\n",
        "padding = 'pre' and 'post' (in and out)\n",
        "\n",
        "encoder_embedding_size = 100\n",
        "\n",
        "decoder_embedding_size = 100\n",
        "\n",
        "hidden_size = 128\n",
        "\n",
        "num_layers = 1\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>loss log</summary>\n",
        "\n",
        "100%|██████████| 50/50 [01:14<00:00,  1.48s/it]\n",
        "EPOCH = 0 \t loss = 7.378298559188843\n",
        "\n",
        "100%|██████████| 50/50 [01:12<00:00,  1.46s/it]\n",
        "EPOCH = 1 \t loss = 4.4149853801727295\n",
        "\n",
        "100%|██████████| 50/50 [01:12<00:00,  1.45s/it]\n",
        "EPOCH = 2 \t loss = 4.219454731941223\n",
        "\n",
        "100%|██████████| 50/50 [01:12<00:00,  1.45s/it]\n",
        "EPOCH = 3 \t loss = 4.088070254325867\n",
        "\n",
        "100%|██████████| 50/50 [01:16<00:00,  1.53s/it]\n",
        "EPOCH = 4 \t loss = 4.004882974624634\n",
        "\n",
        "100%|██████████| 50/50 [01:15<00:00,  1.50s/it]\n",
        "EPOCH = 5 \t loss = 3.9452049922943115\n",
        "\n",
        "100%|██████████| 50/50 [01:13<00:00,  1.47s/it]\n",
        "EPOCH = 6 \t loss = 3.8773948192596435\n",
        "\n",
        "100%|██████████| 50/50 [01:14<00:00,  1.48s/it]\n",
        "EPOCH = 7 \t loss = 3.804203724861145\n",
        "\n",
        "100%|██████████| 50/50 [01:14<00:00,  1.50s/it]\n",
        "EPOCH = 8 \t loss = 3.709712514877319\n",
        "\n",
        "100%|██████████| 50/50 [01:13<00:00,  1.48s/it]\n",
        "EPOCH = 9 \t loss = 3.6215027523040773\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "seq_len = 512\n",
        "\n",
        "padding = 'post'\n",
        "\n",
        "encoder_embedding_size = 300\n",
        "\n",
        "decoder_embedding_size = 300\n",
        "\n",
        "hidden_size = 256\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>loss log</summary>\n",
        "\n",
        "100%|██████████| 50/50 [07:26<00:00,  8.94s/it]\n",
        "EPOCH = 0 \t loss = 5.383958940505981\n",
        "\n",
        "100%|██████████| 50/50 [07:25<00:00,  8.90s/it]\n",
        "EPOCH = 1 \t loss = 3.7594539594650267\n",
        "\n",
        "100%|██████████| 50/50 [07:25<00:00,  8.90s/it]\n",
        "EPOCH = 2 \t loss = 3.5973013925552366\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.90s/it]\n",
        "EPOCH = 3 \t loss = 3.478486728668213\n",
        "\n",
        "100%|██████████| 50/50 [07:25<00:00,  8.90s/it]\n",
        "EPOCH = 4 \t loss = 3.4210835123062133\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n",
        "EPOCH = 5 \t loss = 3.356914539337158\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.90s/it]\n",
        "EPOCH = 6 \t loss = 3.2783570289611816\n",
        "\n",
        "100%|██████████| 50/50 [07:23<00:00,  8.87s/it]\n",
        "EPOCH = 7 \t loss = 3.2372921180725096\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.89s/it]\n",
        "EPOCH = 8 \t loss = 3.199459252357483\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.89s/it]\n",
        "EPOCH = 9 \t loss = 3.1788624906539917\n",
        "\n",
        "100%|██████████| 50/50 [07:23<00:00,  8.87s/it]\n",
        "EPOCH = 10 \t loss = 3.1831029272079467\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n",
        "EPOCH = 11 \t loss = 3.1025032949447633\n",
        "\n",
        "100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n",
        "EPOCH = 12 \t loss = 3.1095044803619385\n",
        "\n",
        "100%|██████████| 50/50 [07:23<00:00,  8.86s/it]\n",
        "EPOCH = 13 \t loss = 3.0869728183746337\n",
        "\n",
        "100%|██████████| 50/50 [07:22<00:00,  8.86s/it]\n",
        "EPOCH = 14 \t loss = 3.08543803691864\n",
        "\n",
        "100%|██████████| 50/50 [07:22<00:00,  8.84s/it]\n",
        "EPOCH = 15 \t loss = 3.0724154567718505\n",
        "\n",
        "100%|██████████| 50/50 [07:21<00:00,  8.83s/it]\n",
        "EPOCH = 16 \t loss = 3.0756219959259035\n",
        "\n",
        "100%|██████████| 50/50 [07:22<00:00,  8.85s/it]\n",
        "EPOCH = 17 \t loss = 3.017907304763794\n",
        "\n",
        "100%|██████████| 50/50 [07:21<00:00,  8.84s/it]\n",
        "EPOCH = 18 \t loss = 3.0001839065551756\n",
        "\n",
        "100%|██████████| 50/50 [07:22<00:00,  8.85s/it]\n",
        "EPOCH = 19 \t loss = 3.021025981903076\n",
        "\n",
        "100%|██████████| 50/50 [07:22<00:00,  8.84s/it]\n",
        "EPOCH = 20 \t loss = 2.9646836137771606\n",
        "\n",
        "100%|██████████| 50/50 [07:22<00:00,  8.84s/it]\n",
        "EPOCH = 21 \t loss = 2.98474328994751\n",
        "\n",
        " 28%|██▊       | 14/50 [02:12<05:40,  9.47s/it]\n",
        "\n",
        " </details>"
      ],
      "metadata": {
        "id": "-TJYdhv4HEBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ],
      "metadata": {
        "id": "ckzBiGAPlYon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, en_vec, output_lang, device, max_length=50):\n",
        "  model.eval()\n",
        "  vec = en_vec[0]\n",
        "  vec = vec.unsqueeze(0)\n",
        "  \n",
        "  # Build encoder hidden, cell state\n",
        "  with torch.no_grad():\n",
        "      hidden, cell = model.encoder(vec)\n",
        "\n",
        "  outputs = [SOS_token]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "      previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "          best_guess = output.argmax(1).item()\n",
        "\n",
        "      outputs.append(best_guess)\n",
        "\n",
        "      # Model predicts it's the end of the sentence\n",
        "      if output.argmax(1).item() == EOS_token:\n",
        "          break\n",
        "  \n",
        "  print(outputs)\n",
        "  translated_sentence = [output_lang.index2word[idx] for idx in outputs]\n",
        "\n",
        "  # remove start token\n",
        "  return translated_sentence"
      ],
      "metadata": {
        "id": "ObAqABe0kVc-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = MyDataset(input_lang, output_lang, pairs[-651:], 128, True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1)"
      ],
      "metadata": {
        "id": "ZTvQvj5llbP-"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, en_vec, output_lang, device, max_length=50):\n",
        "  model.eval()\n",
        "  vec = en_vec[0]\n",
        "  vec = vec.unsqueeze(0)\n",
        "  vec = vec.permute(1, 0)\n",
        "  # print(vec.shape)\n",
        "\n",
        "  # Build encoder hidden, cell state\n",
        "  with torch.no_grad():\n",
        "      hidden, cell = model.encoder(vec)\n",
        "      # print(hidden.shape, cell.shape)\n",
        "\n",
        "  outputs = [SOS_token]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "      previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "          best_guess = output.argmax(1).item()\n",
        "\n",
        "      outputs.append(best_guess)\n",
        "\n",
        "      # Model predicts it's the end of the sentence\n",
        "      if output.argmax(1).item() == EOS_token:\n",
        "          break\n",
        "\n",
        "  translated_sentence = [output_lang.index2word[idx] for idx in outputs]\n",
        "  print(translated_sentence)\n",
        "  return translated_sentence"
      ],
      "metadata": {
        "id": "osrvtFRflNDZ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, ((en_vec, fr_vec), (en, fr)) in enumerate(testloader):\n",
        "  # print(en_vec.shape, fr_vec.shape)\n",
        "  # print(en[0], en_vec[0][:10])\n",
        "  print(fr[0])\n",
        "  translate_sentence(model, en_vec, output_lang, device, max_length=50)\n",
        "  if idx==50: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3pZT6IHlfzz",
        "outputId": "49f31b86-6304-49da-973b-b6ea972b22d8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "je dois me hater .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "il me faut partir .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je dois partir .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je dois etudier .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d une voiture .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d un calin .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "il me faut un travail .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d un emploi .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d un boulot .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "il me faut une carte .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d un stylo .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d argent .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin de peinture .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "il me faut de la peinture .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin de preuves .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "il me faut des preuves .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin de sommeil .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d espace .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin de sucre .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je dois y aller .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je dois partir .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je dois m en aller .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "il me faut de l eau .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai besoin d eau .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je ne perds jamais .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je lis souvent .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je joue du piano .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je lis des livres .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je l ai reecrit .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je le reecrivis .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai dit peut etre .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je vois un livre .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je vois un lion .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je vois une rose .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je vends des chaussures .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je l ai demarre .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je l ai demarree .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je l ai initie .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je l ai initiee .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je m en soucie encore .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je le suppose .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je compatis .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j enseigne ici .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je m en suis doute .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai pris des risques .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai essaye de toutes mes forces .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai essaye ca .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "je comprends .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j ai compris .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j en veux plein .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n",
            "j en veux beaucoup .\n",
            "['<SOS>', 'je', 'est', '.', '.', '.', '<EOS>']\n"
          ]
        }
      ]
    }
  ]
}